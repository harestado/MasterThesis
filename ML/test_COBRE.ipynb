{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from copy import deepcopy\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import f1_score, balanced_accuracy_score\n",
    "\n",
    "from train_model import train_model\n",
    "from validate import validate\n",
    "\n",
    "seed = 42\n",
    "torch.manual_seed(1337)\n",
    "BATCH_SIZE = 5 # må bytte før \"stor\" trening\n",
    "N_EPOCHS = 5\n",
    "LEARNING_RATE = 0.00001\n",
    "DROPOUT_RATE = 0.5\n",
    "NUM_CLASSES = 2\n",
    "\n",
    "device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class COBRE_dataset_subj(Dataset):\n",
    "    \"\"\"This Dataset class loads pairs of COBRE images and labels into the computer memory. The entire subject file is loaded.\n",
    "\n",
    "    Parameters:\n",
    "    - data_path (str): Path to the folder containing images and labels\n",
    "    Returns:\n",
    "    - Tensor: Torch tensor with COBRE time-series\n",
    "    - int: label (0 or 1)\n",
    "\n",
    "   \"\"\"\n",
    "    def __init__(self, data_path):\n",
    "        self.data_path = data_path\n",
    "        self.num_subjects = len(os.listdir(self.data_path))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_subjects\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        subject = os.listdir(self.data_path)[index]\n",
    "        img = self.data_path + '/' + subject + '/nourest.nii'\n",
    "        label = self.data_path + '/' + subject + '/' + subject + '_data.csv'\n",
    "\n",
    "        img = nib.load(img).get_fdata()\n",
    "        img = np.swapaxes(img, 0, 3)\n",
    "        img = torch.from_numpy(img)\n",
    "        img = img.to(torch.float)\n",
    "\n",
    "        label = pd.read_csv(label)\n",
    "        label = label.iloc[0]['subject_type']\n",
    "        # covariates = df.iloc[0]['age', 'gender', 'handedness'].tolist()\n",
    "\n",
    "        ### LABEL\n",
    "        if label == 'Patient':\n",
    "            label = 1\n",
    "        elif label == 'Control':\n",
    "            label = 0\n",
    "        else:\n",
    "            print('Something wrong with data label:', end=' ')\n",
    "            print(label)\n",
    "        \n",
    "        ### AGE, GENDER AND HANDEDNESS\n",
    "        # age = df.iloc[0]['age']\n",
    "        # gender = df.iloc[0]['gender']\n",
    "        # handedness = df.iloc[0]['handedness']\n",
    "\n",
    "        # ### AGE\n",
    "        # # age = (age - 18)/(65-18)\n",
    "\n",
    "        # ### GENDER\n",
    "        # if gender == 'Female':\n",
    "        #     gender = 1\n",
    "        # elif gender == 'Male':\n",
    "        #     gender = 0\n",
    "        # else:\n",
    "        #     print('Something wrong with data label (gender):', end=' ')\n",
    "        #     print(gender)\n",
    "\n",
    "        # ### HANDEDNESS\n",
    "        # if handedness == 'Right':\n",
    "        #     handedness = [1,0]\n",
    "        # elif handedness == 'Left':\n",
    "        #     handedness = [0,1]\n",
    "        # elif handedness == 'Both':\n",
    "        #     handedness = [1,1]\n",
    "        # else:\n",
    "        #     print('Something wrong with data label (handedness):', end=' ')\n",
    "        #     print(handedness)\n",
    "\n",
    "        # covariates = [age, gender]\n",
    "        # for h in handedness:\n",
    "        #     covariates.append(h)\n",
    "        \n",
    "        # covariates = torch.Tensor(covariates)\n",
    "\n",
    "        return img, label #, covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'C:/Users/oscar/OneDrive - University of Bergen/Documents/Master/vsc/COBRE_learning/data/train'\n",
    "val_path = 'C:/Users/oscar/OneDrive - University of Bergen/Documents/Master/vsc/COBRE_learning/data/val'\n",
    "\n",
    "train_data = COBRE_dataset_subj(train_path)\n",
    "val_data = COBRE_dataset_subj(val_path)\n",
    "\n",
    "trainloader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True) #, pin_memory=True, pin_memory_device=device)\n",
    "valloader = DataLoader(val_data, batch_size=1, shuffle=False) #, pin_memory=True, pin_memory_device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Net(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "#         self.conv1 = nn.Conv3d(150, 300, 5) #, padding=5)\n",
    "#         self.pool = nn.MaxPool3d(2, 2)\n",
    "#         self.conv2 = nn.Conv3d(300, 16, 5)\n",
    "#         #self.fc1 = nn.LazyLinear(120)\n",
    "#         self.fc1 = nn.Linear(16 * 2 * 2, 120)\n",
    "#         self.fc2 = nn.Linear(120, 84)\n",
    "#         self.fc3 = nn.Linear(84, 17)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.pool(F.relu(self.conv1(x)))\n",
    "#         x = self.pool(F.relu(self.conv2(x)))\n",
    "#         x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "#         x = F.relu(self.fc1(x))\n",
    "#         x = F.relu(self.fc2(x))\n",
    "#         x = self.fc3(x)\n",
    "#         return x\n",
    "\n",
    "\n",
    "# net = Net()\n",
    "# net = net.to(device)\n",
    "# criterion = nn.CrossEntropyLoss().to(device)\n",
    "# optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Alternativ fra ChatGPT\n",
    "\n",
    "# class SimpleCNN(nn.Module):\n",
    "#     def __init__(self, num_classes):\n",
    "#         super(SimpleCNN, self).__init__()\n",
    "        \n",
    "#         # Convolutional layers\n",
    "#         self.conv1 = nn.Conv3d(in_channels=150, out_channels=50, kernel_size=(3, 3, 3), padding=1)\n",
    "#         self.conv2 = nn.Conv3d(in_channels=50, out_channels=100, kernel_size=(3, 3, 3), padding=1)\n",
    "#         self.conv3 = nn.Conv3d(in_channels=100, out_channels=150, kernel_size=(3, 3, 3), padding=1)\n",
    "        \n",
    "#         # Max pooling layer\n",
    "#         self.pool = nn.MaxPool3d(kernel_size=(2, 2, 2), stride=2)\n",
    "        \n",
    "#         # Fully connected layers\n",
    "#         self.fc1 = nn.Linear(150 * 891, 512)  # Adjust the input size based on your spatial dimensions, 9 * 11 * 9\n",
    "#         self.fc2 = nn.Linear(512, num_classes)\n",
    "        \n",
    "#         # Dropout layer to reduce overfitting\n",
    "#         self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.pool(F.relu(self.conv1(x)))\n",
    "#         x = self.pool(F.relu(self.conv2(x)))\n",
    "#         x = self.pool(F.relu(self.conv3(x)))\n",
    "        \n",
    "#         # Flatten the tensor before fully connected layers\n",
    "#         x = x.view(-1, 150 * 891)  # Adjust the size based on your spatial dimensions\n",
    "        \n",
    "#         x = F.relu(self.fc1(x))\n",
    "#         x = self.dropout(x)\n",
    "#         x = self.fc2(x)\n",
    "        \n",
    "#         return x\n",
    "\n",
    "# # Instantiate the model\n",
    "# num_classes = 2  # Adjust based on the number of classes in your classification task\n",
    "# net = SimpleCNN(num_classes)\n",
    "\n",
    "# # Define loss function and optimizer\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.Adam(net.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### med UNET som inspirasjon\n",
    "\n",
    "# class UNET_inspired(nn.Module):\n",
    "#     def __init__(self, num_classes, in_channels):\n",
    "#         super(UNET_inspired, self).__init__()\n",
    "        \n",
    "#         # Convolutional layers\n",
    "#         self.conv1 = (Conv_layer(in_channels, in_channels*2))\n",
    "#         self.down1 = (Down(in_channels*2, in_channels*4))\n",
    "#         self.down2 = (Down(in_channels*4, in_channels*8))\n",
    "#         self.down3 = (Down(in_channels*8, in_channels*16))\n",
    "#         self.pool = (nn.MaxPool3d(kernel_size=(2,2,2), stride=2))\n",
    "#         self.fc1 = (nn.LazyLinear(num_classes))\n",
    "        \n",
    "#         # Dropout layer to reduce overfitting\n",
    "#         self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         x = self.conv1(x)\n",
    "#         x = self.down1(x)\n",
    "#         x = self.down2(x)\n",
    "#         x = self.down3(x)\n",
    "#         x = self.pool(x)\n",
    "#         x = x.view(-1, 2400 * 80)\n",
    "#         x = self.fc1(x)\n",
    "#         return x\n",
    "\n",
    "\n",
    "# class Conv_layer(nn.Module):\n",
    "#     def __init__(self, in_channels, out_channels):\n",
    "#         super().__init__()\n",
    "#         self.conv = nn.Sequential(\n",
    "#             nn.Conv3d(in_channels=in_channels, out_channels=out_channels, kernel_size=(3, 3, 3), padding=1),\n",
    "#             nn.BatchNorm3d(out_channels),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.Conv3d(in_channels=out_channels, out_channels=out_channels, kernel_size=(3, 3, 3), padding=1),\n",
    "#             nn.BatchNorm3d(out_channels),\n",
    "#             nn.ReLU(inplace=True)\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         return self.conv(x)\n",
    "        \n",
    "# class Down(nn.Module):\n",
    "#     def __init__(self, in_channels, out_channels):\n",
    "#         super().__init__()\n",
    "#         self.pool_conv = nn.Sequential(\n",
    "#             nn.MaxPool3d(kernel_size=(2, 2, 2)),\n",
    "#             Conv_layer(in_channels, out_channels)\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         return self.pool_conv(x)\n",
    "\n",
    "\n",
    "# # Instantiate the model\n",
    "# num_classes = 2  # Adjust based on the number of classes in your classification task\n",
    "# unet = UNET_inspired(num_classes, 150)\n",
    "\n",
    "# # Define loss function and optimizer\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.Adam(unet.parameters(), lr=0.001) #endre på denne for å få ned loss?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### SAVED, 77.777777\n",
    "# ### med UNET som inspirasjon, med Mari sin hjelp\n",
    "# ### kan ta inspirasjon fra denne: https://doi.org/gjj4xv\n",
    "\n",
    "# class UNET_Mari(nn.Module):\n",
    "#     def __init__(self, num_classes, in_channels):\n",
    "#         super(UNET_Mari, self).__init__()\n",
    "        \n",
    "#         # Convolutional layers\n",
    "#         self.conv1 = (nn.Conv3d(in_channels, 10, kernel_size=(3, 3, 3), padding=1))\n",
    "#         self.conv1_2 = (nn.Conv3d(10, 1, kernel_size=(3, 3, 3), padding=1))\n",
    "#         self.pool1 = (nn.MaxPool3d(kernel_size=(2,2,2), stride=2))\n",
    "#         self.dropout = (nn.Dropout(0.5))\n",
    "#         self.conv2 = (nn.Conv2d(47, 1, kernel_size=(3, 3), padding=1))\n",
    "#         # also more layers here, perhaps\n",
    "#         self.pool2 = (nn.MaxPool2d(kernel_size=(2,2), stride=2))\n",
    "#         self.fc1 = (nn.Linear(19*19, 4*4)) # one functional layer or two?\n",
    "#         self.fc2 = (nn.Linear(4*4, num_classes))\n",
    "\n",
    "#     def forward(self, x): # should ReLU be used in every step here?\n",
    "#         x = F.relu(self.conv1(x))\n",
    "#         x = F.relu(self.conv1_2(x))\n",
    "#         x = self.dropout(x)\n",
    "#         x = self.pool1(x)\n",
    "#         x = torch.squeeze(x, dim=1)\n",
    "#         x = F.relu(self.conv2(x))\n",
    "#         x = self.dropout(x)\n",
    "#         x = self.pool2(x)\n",
    "#         x = torch.flatten(x, start_dim=1)\n",
    "#         x = F.relu(self.fc1(x))\n",
    "#         x = self.fc2(x)\n",
    "#         return x\n",
    "\n",
    "# # Instantiate the model\n",
    "# num_classes = 2  # Adjust based on the number of classes in your classification task\n",
    "# unet = UNET_Mari(num_classes, 150)\n",
    "\n",
    "# # Define loss function and optimizer\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.Adam(unet.parameters(), lr=0.0001) #endre på lr for å få ned loss?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 77.7777 modified\n",
    "### med UNET som inspirasjon, med Mari sin hjelp\n",
    "### kan ta inspirasjon fra denne: https://doi.org/gjj4xv\n",
    "\n",
    "class UNET_Mari(nn.Module):\n",
    "    def __init__(self, num_classes, dropout_rate):\n",
    "        super(UNET_Mari, self).__init__()\n",
    "        \n",
    "        # Convolutional layers\n",
    "        self.conv1 = (nn.Conv3d(150, 10, kernel_size=(3, 3, 3), padding=1))\n",
    "        self.conv1_2 = (nn.Conv3d(10, 1, kernel_size=(3, 3, 3), padding=1))\n",
    "        self.pool1 = (nn.MaxPool3d(kernel_size=(2,2,2), stride=2))\n",
    "        self.dropout = (nn.Dropout(dropout_rate))\n",
    "        self.conv2 = (nn.Conv2d(47, 1, kernel_size=(3, 3), padding=1))\n",
    "        # also more layers here, perhaps\n",
    "        self.pool2 = (nn.MaxPool2d(kernel_size=(2,2), stride=2))\n",
    "        self.fc1 = (nn.Linear(19*19, 4*4)) # one functional layer or two?\n",
    "        self.fc2 = (nn.Linear(4*4, num_classes))\n",
    "\n",
    "    def forward(self, x): # should ReLU be used in every step here?\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv1_2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.pool1(x)\n",
    "        x = torch.squeeze(x, dim=1)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.pool2(x)\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate the model\n",
    "unet = UNET_Mari(NUM_CLASSES, dropout_rate=DROPOUT_RATE)\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.Adam(unet.parameters(), lr=0.00001) #endre på lr for å få ned loss?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params, losses_val, losses_train = train_model(unet, device, trainloader, valloader, N_EPOCHS, learning_rate=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = UNET_Mari(NUM_CLASSES, dropout_rate=DROPOUT_RATE)\n",
    "# best_model.load_state_dict(torch.load('models/best_model_params_nou.pt'))\n",
    "best_model.load_state_dict(best_params)\n",
    "best_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true, y_pred = validate(best_model, device, valloader, 'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_train, y_pred_train = validate(best_model, device, trainloader, 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Val')\n",
    "print('F1-score:', f1_score(y_true, y_pred, average=\"weighted\")*100)\n",
    "print('Balanced accuracy score:', balanced_accuracy_score(y_true, y_pred)*100)\n",
    "print()\n",
    "print('Train')\n",
    "print('F1-score:', f1_score(y_true_train, y_pred_train, average=\"weighted\")*100)\n",
    "print('Balanced accuracy score:', balanced_accuracy_score(y_true_train, y_pred_train)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Val')\n",
    "print('True:', y_true)\n",
    "unique, count = np.unique(y_true, return_counts=True)\n",
    "print(unique, count)\n",
    "print('Pred:', y_pred)\n",
    "unique, count = np.unique(y_pred, return_counts=True)\n",
    "print(unique, count)\n",
    "print('Missed:', abs(count[0]-count[1])//2)\n",
    "unique, count = np.unique([t==y for t,y in zip(y_true, y_pred)], return_counts=True)\n",
    "print(unique, count)\n",
    "print()\n",
    "print('Train')\n",
    "print('True:', y_true_train)\n",
    "unique, count = np.unique(y_true_train, return_counts=True)\n",
    "print(unique, count)\n",
    "print('Pred:', y_pred_train)\n",
    "unique, count = np.unique(y_pred_train, return_counts=True)\n",
    "print(unique, count)\n",
    "print('Missed:', abs(count[0]-count[1])//2)\n",
    "unique, count = np.unique([t==y for t,y in zip(y_true_train, y_pred_train)], return_counts=True)\n",
    "print(unique, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_losses = torch.Tensor([losses_val], device='cpu')\n",
    "train_losses = torch.Tensor([losses_train], device='cpu')\n",
    "colors = ['r', 'b', 'g']\n",
    "\n",
    "for i in range(len(validation_losses)):\n",
    "    xvalues = np.linspace(0, N_EPOCHS, len(validation_losses[i]))\n",
    "    yvalues01 = validation_losses[i]\n",
    "    yvalues02 = train_losses[i]\n",
    "    name = \"model %i \"%(i+1)\n",
    "\n",
    "    plt.plot(xvalues, yvalues01, label=name + \"val loss\", color='r')\n",
    "    plt.plot(xvalues, yvalues02, label=name + \"train loss\", color='b', linestyle=\"dashed\")\n",
    "\n",
    "plt.title('Validation  and training loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('value')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
